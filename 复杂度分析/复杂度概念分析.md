#### 复杂度分析的起源
1965年哈特马尼斯和斯坦恩斯提出了计算复杂度的概念，论文
https://pdfs.semanticscholar.org/1ce8/9af300d9a7c64d3ee06175b24ca97763f9f2.pdf
其实要追本溯源是需要耐心和时间，同时英文要好。

#### 复杂度的内涵、外延
内涵：维基百科：算法的运行时间
外延：Tn = O(fn) 
fn代表，每行代码的执行次数总和

### 复杂度分析的预先要求

算法的执行效率，是算法代码执行的时间。这句话怎么讲？有一个标准吧，不然谁知道每行代码具体的执行时间是什么？

代码示例
```
	int cal(int n) {
		int sum = 0;
		int i = 1;
		for (; i <= n; ++i) {
			sum = sum + i;
		}
		return sum;
	}
```

第2行到第4行代码是3unit_time,第五行，2n*unit_time +2n*n*unit_time



每个函数、也就是每个模块可以判断大概执行的时间复杂度是多少。
写完下面的代码，也不知道怎么滴，好像有点感受了对于时间复杂度。
```
//这个函数的时间复杂度是O(n)
function cal(n) {
		let sum = 0;
		let i = 1;
		for (i; i<= n; ++i) {
			sum = sum + i;
		}
		return sum;
	}
```

时间复杂度分析，分析的是代码执行的时间，怎么分析一段代码的时间复杂度？

1.只关注循环执行次数最多的一段代码
我们通常会忽略掉公式中的常量、低阶、系数，对应一两行代码、一次循环的代码、循环次数最多一段代码。

例如
```
1  function cal(n) {
2  	let sum = 0;
3  	let i = 1;
4  	for(i; i <= n ; ++i) {
5  		sum = sum + i
6  	}
7  	return sum
8  }
```
其中第2行和第3行代码都是常量级的执行时间，与n的大小无关，所以对于时间复杂度没有影响。循环次数最多的是第4行和第5行代码，所以这块代码要重点分析。这两行代码被执行了n次，所以总的时间复杂度就是O(n)。

根据时间的必要难度，提取的必要难度。用自己的话来解释一下「时间复杂度」这个概念，

时间复杂度这个概念，是建立在数据结构和算法基础之上的一个概念。可以说，数据结构和算法先要存在这个世上，才有时间复杂度的故事。学习这个概念不要忘了它的根基，之后一系列的在时间复杂度延伸的概念都离不开它的根基。

就像，欧几里得的《几何原本》的那五条公理，“用公理化的体系，不但奠定了整个几何学的基础，也制定了整个科学研究的方法。”

现在可以讲解，时间复杂度概念的内涵和外延了，时间复杂度的内涵：代码的运行时间，也是算法的执行效率。
时间复杂度的外延：T(n) = O(fn),T(n)

表示代码执行的总时间，fn代表代码执行的次数总和。O代表，代码执行的总时间与代码执行的总次数成正比。

理论，知道了，就要去实践了，知行合一。

记得，时间复杂度的概念和外延。时间复杂度的预先条件，必然是数据结构与算法。

T(n) = O(f(n))
f(n)表示代码执行的总次数，可以是一次函数，可以是常量、也可以说二阶函数、多阶函数。
你知道，现在的变量完全在于f(n),如果f(n)是静止的，那么时间复杂度也不必要去分析了

王争老师给出了三个比较实用的方法，来分析一段代码的时间复杂度？

1.只关注循环次数最多的代码的一段代码
2.加法法则：总复杂度等于量级最大的那段代码的复杂度
3.乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

这三个实用方法的前提是：T(n) = O(f(n)),根据f(n)的变化来制定的三个法则。

f(n) = 2n + 2  f(n) = logn
f(n) = 2n*n + 2n + 2
f(n) = n*n*n
f(n) = n*logn







